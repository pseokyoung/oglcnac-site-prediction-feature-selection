{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc03987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# function ConnectButton(){\n",
    "#     console.log(\"Connect pushed\");\n",
    "#     document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n",
    "# }\n",
    "\n",
    "# setInterval(ConnectButton,60000);\n",
    "# '''\n",
    "\n",
    "# from google.colab import drive\n",
    "# from os import chdir\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# project_path = '/content/drive/MyDrive/Gproject/o-linked-site-prediction-feature-augment'\n",
    "# chdir(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ae3da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14638260538527346589\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9973006336\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9689848030570155448\n",
      "physical_device_desc: \"device: 0, name: NVIDIA RTX 4000 Ada Generation Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b246081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set seed for the reproducible result\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41490bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of initial proteins: 104\n",
      "['A2ABU4', 'A2AHJ4', 'A2AKB9', 'A2AQ25', 'E9Q1P8', 'E9Q5G3', 'O08537', 'O09061', 'O35303', 'O70263']\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/integrated_features' # we will get names from the augmented proteins\n",
    "protein_names = [x.split('.')[0] for x in os.listdir(data_dir) if x.split('.')[1] == 'csv'] # get protein name list to be processed for building machine learning models\n",
    "print('the number of initial proteins:', len(protein_names))\n",
    "print(protein_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55978831",
   "metadata": {},
   "source": [
    "## hyper parameter optimization by K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71be2f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from ml_models import *\n",
    "\n",
    "epochs = 1000\n",
    "from keras.callbacks import EarlyStopping\n",
    "patience = 30\n",
    "callbacks = [EarlyStopping(patience=patience, restore_best_weights=True, monitor='val_loss')]\n",
    "\n",
    "test_size = 0.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af4278b",
   "metadata": {},
   "source": [
    "### set initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99162761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7789ffcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial parameters\n",
      "rnn_layers     : 5\n",
      "rnn_neurons    : 64\n",
      "dnn_layers     : 3\n",
      "dnn_neurons    : 64\n",
      "activation     : softmax\n",
      "loss           : categorical_crossentropy\n",
      "metrics        : accuracy\n",
      "optimizer_type : Adam\n",
      "learning_rate  : 0.001\n",
      "regularizer    : {'input': None, 'hidden': None, 'bias': None}\n",
      "window_size    : 10\n"
     ]
    }
   ],
   "source": [
    "initial_params = default_params.copy()\n",
    "initial_params.update({\n",
    "    'window_size'    : 10,\n",
    "    'rnn_layers'     : 5,\n",
    "    'rnn_neurons'    : 64,\n",
    "    'dnn_layers'     : 3,\n",
    "    'dnn_neurons'    : 64\n",
    "    })\n",
    "\n",
    "print('initial parameters')\n",
    "for key, value in initial_params.items():\n",
    "    print(f'{key:<14} : {value}')\n",
    "\n",
    "regularizers = [\n",
    "    {'input': None, 'hidden': None, 'bias': None},\n",
    "\n",
    "    {'input': 'L21_0.001', 'hidden': None,           'bias': None},\n",
    "    {'input': 'L21_0.001', 'hidden': 'L21_0.001', 'bias': None},\n",
    "    {'input':  'L1_0.001', 'hidden': None,           'bias': None},\n",
    "    {'input':  'L1_0.001', 'hidden':  'L1_0.001', 'bias': None},\n",
    "\n",
    "    {'input': 'L21_0.0001', 'hidden': None,           'bias': None},\n",
    "    {'input': 'L21_0.0001', 'hidden': 'L21_0.0001', 'bias': None},\n",
    "    {'input':  'L1_0.0001', 'hidden': None,           'bias': None},\n",
    "    {'input':  'L1_0.0001', 'hidden':  'L1_0.0001', 'bias': None},\n",
    "\n",
    "    {'input': 'L21_0.00001', 'hidden': None,           'bias': None},\n",
    "    {'input': 'L21_0.00001', 'hidden': 'L21_0.00001', 'bias': None},\n",
    "    {'input':  'L1_0.00001', 'hidden': None,           'bias': None},\n",
    "    {'input':  'L1_0.00001', 'hidden':  'L1_0.00001', 'bias': None},\n",
    "\n",
    "    {'input': 'L21_0.000001', 'hidden': None,           'bias': None},\n",
    "    {'input': 'L21_0.000001', 'hidden': 'L21_0.000001', 'bias': None},\n",
    "    {'input':  'L1_0.000001', 'hidden': None,           'bias': None},\n",
    "    {'input':  'L1_0.000001', 'hidden':  'L1_0.000001', 'bias': None},\n",
    "\n",
    "    {'input': 'L21_0.0000001', 'hidden': None,           'bias': None},\n",
    "    {'input': 'L21_0.0000001', 'hidden': 'L21_0.0000001', 'bias': None},\n",
    "    {'input':  'L1_0.0000001', 'hidden': None,           'bias': None},\n",
    "    {'input':  'L1_0.0000001', 'hidden':  'L1_0.0000001', 'bias': None},\n",
    "\n",
    "    {'input': 'L21_0.00000001', 'hidden': None,           'bias': None},\n",
    "    {'input': 'L21_0.00000001', 'hidden': 'L21_0.00000001', 'bias': None},\n",
    "    {'input':  'L1_0.00000001', 'hidden': None,           'bias': None},\n",
    "    {'input':  'L1_0.00000001', 'hidden':  'L1_0.00000001', 'bias': None},\n",
    "\n",
    "    {'input': 'L21_0.000000001', 'hidden': None,           'bias': None},\n",
    "    {'input': 'L21_0.000000001', 'hidden': 'L21_0.000000001', 'bias': None},\n",
    "    {'input':  'L1_0.000000001', 'hidden': None,           'bias': None},\n",
    "    {'input':  'L1_0.000000001', 'hidden':  'L1_0.000000001', 'bias': None}\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f9241",
   "metadata": {},
   "source": [
    "## set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00ef1d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of augmented features: 498\n",
      "continuous features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'number_hydrophobic_0A',\n",
       " 1: 'number_hydrophilic_0A',\n",
       " 2: 'number_polar_0A',\n",
       " 3: 'number_aromatic_0A',\n",
       " 4: 'number_aliphatic_0A',\n",
       " 5: 'number_charged_0A',\n",
       " 6: 'number_positive_0A',\n",
       " 7: 'number_negative_0A',\n",
       " 8: 'number_gly_0A',\n",
       " 9: 'number_very_small_0A',\n",
       " 10: 'number_small_0A',\n",
       " 11: 'number_normal_0A',\n",
       " 12: 'number_long_0A',\n",
       " 13: 'number_pro_0A',\n",
       " 14: 'number_A_polar_uncharged_with_hydroxyl_group_0A',\n",
       " 15: 'number_b_polar_uncharged_with_amide_0A',\n",
       " 16: 'number_d_negatively_charged_polar_0A',\n",
       " 17: 'number_e_non_polar_suffered_0A',\n",
       " 18: 'number_f_non_polar_aromatic_0A',\n",
       " 19: 'number_ala_0A',\n",
       " 20: 'number_cys_0A',\n",
       " 21: 'number_asp_0A',\n",
       " 22: 'number_glu_0A',\n",
       " 23: 'number_phe_0A',\n",
       " 24: 'number_his_0A',\n",
       " 25: 'number_ile_0A',\n",
       " 26: 'number_lys_0A',\n",
       " 27: 'number_leu_0A',\n",
       " 28: 'number_met_0A',\n",
       " 29: 'number_asn_0A',\n",
       " 30: 'number_gln_0A',\n",
       " 31: 'number_arg_0A',\n",
       " 32: 'number_ser_0A',\n",
       " 33: 'number_thr_0A',\n",
       " 34: 'number_val_0A',\n",
       " 35: 'number_trp_0A',\n",
       " 36: 'number_tyr_0A',\n",
       " 37: 'sasa_hydrophobic_0A',\n",
       " 38: 'sasa_hydrophilic_0A',\n",
       " 39: 'sasa_polar_0A',\n",
       " 40: 'sasa_aromatic_0A',\n",
       " 41: 'sasa_aliphatic_0A',\n",
       " 42: 'sasa_charged_0A',\n",
       " 43: 'sasa_positive_0A',\n",
       " 44: 'sasa_negative_0A',\n",
       " 45: 'sasa_gly_0A',\n",
       " 46: 'sasa_very_small_0A',\n",
       " 47: 'sasa_small_0A',\n",
       " 48: 'sasa_normal_0A',\n",
       " 49: 'sasa_long_0A',\n",
       " 50: 'sasa_pro_0A',\n",
       " 51: 'sasa_A_polar_uncharged_with_hydroxyl_group_0A',\n",
       " 52: 'sasa_b_polar_uncharged_with_amide_0A',\n",
       " 53: 'sasa_d_negatively_charged_polar_0A',\n",
       " 54: 'sasa_e_non_polar_suffered_0A',\n",
       " 55: 'sasa_f_non_polar_aromatic_0A',\n",
       " 56: 'sasa_ala_0A',\n",
       " 57: 'sasa_cys_0A',\n",
       " 58: 'sasa_asp_0A',\n",
       " 59: 'sasa_glu_0A',\n",
       " 60: 'sasa_phe_0A',\n",
       " 61: 'sasa_his_0A',\n",
       " 62: 'sasa_ile_0A',\n",
       " 63: 'sasa_lys_0A',\n",
       " 64: 'sasa_leu_0A',\n",
       " 65: 'sasa_met_0A',\n",
       " 66: 'sasa_asn_0A',\n",
       " 67: 'sasa_gln_0A',\n",
       " 68: 'sasa_arg_0A',\n",
       " 69: 'sasa_ser_0A',\n",
       " 70: 'sasa_thr_0A',\n",
       " 71: 'sasa_val_0A',\n",
       " 72: 'sasa_trp_0A',\n",
       " 73: 'sasa_tyr_0A',\n",
       " 74: 'sasa_back_0A',\n",
       " 75: 'sasa_side_0A',\n",
       " 76: 'sasa_target_ser_thr_0A',\n",
       " 77: 'net_charge_all_0A',\n",
       " 78: 'net_charge_backbone_0A',\n",
       " 79: 'net_charge_sidechain_0A',\n",
       " 80: 'net_charge_all_exposed_0A',\n",
       " 81: 'net_charge_backbone_exposed_0A',\n",
       " 82: 'net_charge_sidechain_exposed_0A',\n",
       " 83: 'number_hydrophobic_5A',\n",
       " 84: 'number_hydrophilic_5A',\n",
       " 85: 'number_polar_5A',\n",
       " 86: 'number_aromatic_5A',\n",
       " 87: 'number_aliphatic_5A',\n",
       " 88: 'number_charged_5A',\n",
       " 89: 'number_positive_5A',\n",
       " 90: 'number_negative_5A',\n",
       " 91: 'number_gly_5A',\n",
       " 92: 'number_very_small_5A',\n",
       " 93: 'number_small_5A',\n",
       " 94: 'number_normal_5A',\n",
       " 95: 'number_long_5A',\n",
       " 96: 'number_pro_5A',\n",
       " 97: 'number_A_polar_uncharged_with_hydroxyl_group_5A',\n",
       " 98: 'number_b_polar_uncharged_with_amide_5A',\n",
       " 99: 'number_d_negatively_charged_polar_5A',\n",
       " 100: 'number_e_non_polar_suffered_5A',\n",
       " 101: 'number_f_non_polar_aromatic_5A',\n",
       " 102: 'number_ala_5A',\n",
       " 103: 'number_cys_5A',\n",
       " 104: 'number_asp_5A',\n",
       " 105: 'number_glu_5A',\n",
       " 106: 'number_phe_5A',\n",
       " 107: 'number_his_5A',\n",
       " 108: 'number_ile_5A',\n",
       " 109: 'number_lys_5A',\n",
       " 110: 'number_leu_5A',\n",
       " 111: 'number_met_5A',\n",
       " 112: 'number_asn_5A',\n",
       " 113: 'number_gln_5A',\n",
       " 114: 'number_arg_5A',\n",
       " 115: 'number_ser_5A',\n",
       " 116: 'number_thr_5A',\n",
       " 117: 'number_val_5A',\n",
       " 118: 'number_trp_5A',\n",
       " 119: 'number_tyr_5A',\n",
       " 120: 'sasa_hydrophobic_5A',\n",
       " 121: 'sasa_hydrophilic_5A',\n",
       " 122: 'sasa_polar_5A',\n",
       " 123: 'sasa_aromatic_5A',\n",
       " 124: 'sasa_aliphatic_5A',\n",
       " 125: 'sasa_charged_5A',\n",
       " 126: 'sasa_positive_5A',\n",
       " 127: 'sasa_negative_5A',\n",
       " 128: 'sasa_gly_5A',\n",
       " 129: 'sasa_very_small_5A',\n",
       " 130: 'sasa_small_5A',\n",
       " 131: 'sasa_normal_5A',\n",
       " 132: 'sasa_long_5A',\n",
       " 133: 'sasa_pro_5A',\n",
       " 134: 'sasa_A_polar_uncharged_with_hydroxyl_group_5A',\n",
       " 135: 'sasa_b_polar_uncharged_with_amide_5A',\n",
       " 136: 'sasa_d_negatively_charged_polar_5A',\n",
       " 137: 'sasa_e_non_polar_suffered_5A',\n",
       " 138: 'sasa_f_non_polar_aromatic_5A',\n",
       " 139: 'sasa_ala_5A',\n",
       " 140: 'sasa_cys_5A',\n",
       " 141: 'sasa_asp_5A',\n",
       " 142: 'sasa_glu_5A',\n",
       " 143: 'sasa_phe_5A',\n",
       " 144: 'sasa_his_5A',\n",
       " 145: 'sasa_ile_5A',\n",
       " 146: 'sasa_lys_5A',\n",
       " 147: 'sasa_leu_5A',\n",
       " 148: 'sasa_met_5A',\n",
       " 149: 'sasa_asn_5A',\n",
       " 150: 'sasa_gln_5A',\n",
       " 151: 'sasa_arg_5A',\n",
       " 152: 'sasa_ser_5A',\n",
       " 153: 'sasa_thr_5A',\n",
       " 154: 'sasa_val_5A',\n",
       " 155: 'sasa_trp_5A',\n",
       " 156: 'sasa_tyr_5A',\n",
       " 157: 'sasa_back_5A',\n",
       " 158: 'sasa_side_5A',\n",
       " 159: 'sasa_target_ser_thr_5A',\n",
       " 160: 'net_charge_all_5A',\n",
       " 161: 'net_charge_backbone_5A',\n",
       " 162: 'net_charge_sidechain_5A',\n",
       " 163: 'net_charge_all_exposed_5A',\n",
       " 164: 'net_charge_backbone_exposed_5A',\n",
       " 165: 'net_charge_sidechain_exposed_5A',\n",
       " 166: 'number_hydrophobic_10A',\n",
       " 167: 'number_hydrophilic_10A',\n",
       " 168: 'number_polar_10A',\n",
       " 169: 'number_aromatic_10A',\n",
       " 170: 'number_aliphatic_10A',\n",
       " 171: 'number_charged_10A',\n",
       " 172: 'number_positive_10A',\n",
       " 173: 'number_negative_10A',\n",
       " 174: 'number_gly_10A',\n",
       " 175: 'number_very_small_10A',\n",
       " 176: 'number_small_10A',\n",
       " 177: 'number_normal_10A',\n",
       " 178: 'number_long_10A',\n",
       " 179: 'number_pro_10A',\n",
       " 180: 'number_A_polar_uncharged_with_hydroxyl_group_10A',\n",
       " 181: 'number_b_polar_uncharged_with_amide_10A',\n",
       " 182: 'number_d_negatively_charged_polar_10A',\n",
       " 183: 'number_e_non_polar_suffered_10A',\n",
       " 184: 'number_f_non_polar_aromatic_10A',\n",
       " 185: 'number_ala_10A',\n",
       " 186: 'number_cys_10A',\n",
       " 187: 'number_asp_10A',\n",
       " 188: 'number_glu_10A',\n",
       " 189: 'number_phe_10A',\n",
       " 190: 'number_his_10A',\n",
       " 191: 'number_ile_10A',\n",
       " 192: 'number_lys_10A',\n",
       " 193: 'number_leu_10A',\n",
       " 194: 'number_met_10A',\n",
       " 195: 'number_asn_10A',\n",
       " 196: 'number_gln_10A',\n",
       " 197: 'number_arg_10A',\n",
       " 198: 'number_ser_10A',\n",
       " 199: 'number_thr_10A',\n",
       " 200: 'number_val_10A',\n",
       " 201: 'number_trp_10A',\n",
       " 202: 'number_tyr_10A',\n",
       " 203: 'sasa_hydrophobic_10A',\n",
       " 204: 'sasa_hydrophilic_10A',\n",
       " 205: 'sasa_polar_10A',\n",
       " 206: 'sasa_aromatic_10A',\n",
       " 207: 'sasa_aliphatic_10A',\n",
       " 208: 'sasa_charged_10A',\n",
       " 209: 'sasa_positive_10A',\n",
       " 210: 'sasa_negative_10A',\n",
       " 211: 'sasa_gly_10A',\n",
       " 212: 'sasa_very_small_10A',\n",
       " 213: 'sasa_small_10A',\n",
       " 214: 'sasa_normal_10A',\n",
       " 215: 'sasa_long_10A',\n",
       " 216: 'sasa_pro_10A',\n",
       " 217: 'sasa_A_polar_uncharged_with_hydroxyl_group_10A',\n",
       " 218: 'sasa_b_polar_uncharged_with_amide_10A',\n",
       " 219: 'sasa_d_negatively_charged_polar_10A',\n",
       " 220: 'sasa_e_non_polar_suffered_10A',\n",
       " 221: 'sasa_f_non_polar_aromatic_10A',\n",
       " 222: 'sasa_ala_10A',\n",
       " 223: 'sasa_cys_10A',\n",
       " 224: 'sasa_asp_10A',\n",
       " 225: 'sasa_glu_10A',\n",
       " 226: 'sasa_phe_10A',\n",
       " 227: 'sasa_his_10A',\n",
       " 228: 'sasa_ile_10A',\n",
       " 229: 'sasa_lys_10A',\n",
       " 230: 'sasa_leu_10A',\n",
       " 231: 'sasa_met_10A',\n",
       " 232: 'sasa_asn_10A',\n",
       " 233: 'sasa_gln_10A',\n",
       " 234: 'sasa_arg_10A',\n",
       " 235: 'sasa_ser_10A',\n",
       " 236: 'sasa_thr_10A',\n",
       " 237: 'sasa_val_10A',\n",
       " 238: 'sasa_trp_10A',\n",
       " 239: 'sasa_tyr_10A',\n",
       " 240: 'sasa_back_10A',\n",
       " 241: 'sasa_side_10A',\n",
       " 242: 'sasa_target_ser_thr_10A',\n",
       " 243: 'net_charge_all_10A',\n",
       " 244: 'net_charge_backbone_10A',\n",
       " 245: 'net_charge_sidechain_10A',\n",
       " 246: 'net_charge_all_exposed_10A',\n",
       " 247: 'net_charge_backbone_exposed_10A',\n",
       " 248: 'net_charge_sidechain_exposed_10A',\n",
       " 249: 'number_hydrophobic_15A',\n",
       " 250: 'number_hydrophilic_15A',\n",
       " 251: 'number_polar_15A',\n",
       " 252: 'number_aromatic_15A',\n",
       " 253: 'number_aliphatic_15A',\n",
       " 254: 'number_charged_15A',\n",
       " 255: 'number_positive_15A',\n",
       " 256: 'number_negative_15A',\n",
       " 257: 'number_gly_15A',\n",
       " 258: 'number_very_small_15A',\n",
       " 259: 'number_small_15A',\n",
       " 260: 'number_normal_15A',\n",
       " 261: 'number_long_15A',\n",
       " 262: 'number_pro_15A',\n",
       " 263: 'number_A_polar_uncharged_with_hydroxyl_group_15A',\n",
       " 264: 'number_b_polar_uncharged_with_amide_15A',\n",
       " 265: 'number_d_negatively_charged_polar_15A',\n",
       " 266: 'number_e_non_polar_suffered_15A',\n",
       " 267: 'number_f_non_polar_aromatic_15A',\n",
       " 268: 'number_ala_15A',\n",
       " 269: 'number_cys_15A',\n",
       " 270: 'number_asp_15A',\n",
       " 271: 'number_glu_15A',\n",
       " 272: 'number_phe_15A',\n",
       " 273: 'number_his_15A',\n",
       " 274: 'number_ile_15A',\n",
       " 275: 'number_lys_15A',\n",
       " 276: 'number_leu_15A',\n",
       " 277: 'number_met_15A',\n",
       " 278: 'number_asn_15A',\n",
       " 279: 'number_gln_15A',\n",
       " 280: 'number_arg_15A',\n",
       " 281: 'number_ser_15A',\n",
       " 282: 'number_thr_15A',\n",
       " 283: 'number_val_15A',\n",
       " 284: 'number_trp_15A',\n",
       " 285: 'number_tyr_15A',\n",
       " 286: 'sasa_hydrophobic_15A',\n",
       " 287: 'sasa_hydrophilic_15A',\n",
       " 288: 'sasa_polar_15A',\n",
       " 289: 'sasa_aromatic_15A',\n",
       " 290: 'sasa_aliphatic_15A',\n",
       " 291: 'sasa_charged_15A',\n",
       " 292: 'sasa_positive_15A',\n",
       " 293: 'sasa_negative_15A',\n",
       " 294: 'sasa_gly_15A',\n",
       " 295: 'sasa_very_small_15A',\n",
       " 296: 'sasa_small_15A',\n",
       " 297: 'sasa_normal_15A',\n",
       " 298: 'sasa_long_15A',\n",
       " 299: 'sasa_pro_15A',\n",
       " 300: 'sasa_A_polar_uncharged_with_hydroxyl_group_15A',\n",
       " 301: 'sasa_b_polar_uncharged_with_amide_15A',\n",
       " 302: 'sasa_d_negatively_charged_polar_15A',\n",
       " 303: 'sasa_e_non_polar_suffered_15A',\n",
       " 304: 'sasa_f_non_polar_aromatic_15A',\n",
       " 305: 'sasa_ala_15A',\n",
       " 306: 'sasa_cys_15A',\n",
       " 307: 'sasa_asp_15A',\n",
       " 308: 'sasa_glu_15A',\n",
       " 309: 'sasa_phe_15A',\n",
       " 310: 'sasa_his_15A',\n",
       " 311: 'sasa_ile_15A',\n",
       " 312: 'sasa_lys_15A',\n",
       " 313: 'sasa_leu_15A',\n",
       " 314: 'sasa_met_15A',\n",
       " 315: 'sasa_asn_15A',\n",
       " 316: 'sasa_gln_15A',\n",
       " 317: 'sasa_arg_15A',\n",
       " 318: 'sasa_ser_15A',\n",
       " 319: 'sasa_thr_15A',\n",
       " 320: 'sasa_val_15A',\n",
       " 321: 'sasa_trp_15A',\n",
       " 322: 'sasa_tyr_15A',\n",
       " 323: 'sasa_back_15A',\n",
       " 324: 'sasa_side_15A',\n",
       " 325: 'sasa_target_ser_thr_15A',\n",
       " 326: 'net_charge_all_15A',\n",
       " 327: 'net_charge_backbone_15A',\n",
       " 328: 'net_charge_sidechain_15A',\n",
       " 329: 'net_charge_all_exposed_15A',\n",
       " 330: 'net_charge_backbone_exposed_15A',\n",
       " 331: 'net_charge_sidechain_exposed_15A',\n",
       " 332: 'number_hydrophobic_20A',\n",
       " 333: 'number_hydrophilic_20A',\n",
       " 334: 'number_polar_20A',\n",
       " 335: 'number_aromatic_20A',\n",
       " 336: 'number_aliphatic_20A',\n",
       " 337: 'number_charged_20A',\n",
       " 338: 'number_positive_20A',\n",
       " 339: 'number_negative_20A',\n",
       " 340: 'number_gly_20A',\n",
       " 341: 'number_very_small_20A',\n",
       " 342: 'number_small_20A',\n",
       " 343: 'number_normal_20A',\n",
       " 344: 'number_long_20A',\n",
       " 345: 'number_pro_20A',\n",
       " 346: 'number_A_polar_uncharged_with_hydroxyl_group_20A',\n",
       " 347: 'number_b_polar_uncharged_with_amide_20A',\n",
       " 348: 'number_d_negatively_charged_polar_20A',\n",
       " 349: 'number_e_non_polar_suffered_20A',\n",
       " 350: 'number_f_non_polar_aromatic_20A',\n",
       " 351: 'number_ala_20A',\n",
       " 352: 'number_cys_20A',\n",
       " 353: 'number_asp_20A',\n",
       " 354: 'number_glu_20A',\n",
       " 355: 'number_phe_20A',\n",
       " 356: 'number_his_20A',\n",
       " 357: 'number_ile_20A',\n",
       " 358: 'number_lys_20A',\n",
       " 359: 'number_leu_20A',\n",
       " 360: 'number_met_20A',\n",
       " 361: 'number_asn_20A',\n",
       " 362: 'number_gln_20A',\n",
       " 363: 'number_arg_20A',\n",
       " 364: 'number_ser_20A',\n",
       " 365: 'number_thr_20A',\n",
       " 366: 'number_val_20A',\n",
       " 367: 'number_trp_20A',\n",
       " 368: 'number_tyr_20A',\n",
       " 369: 'sasa_hydrophobic_20A',\n",
       " 370: 'sasa_hydrophilic_20A',\n",
       " 371: 'sasa_polar_20A',\n",
       " 372: 'sasa_aromatic_20A',\n",
       " 373: 'sasa_aliphatic_20A',\n",
       " 374: 'sasa_charged_20A',\n",
       " 375: 'sasa_positive_20A',\n",
       " 376: 'sasa_negative_20A',\n",
       " 377: 'sasa_gly_20A',\n",
       " 378: 'sasa_very_small_20A',\n",
       " 379: 'sasa_small_20A',\n",
       " 380: 'sasa_normal_20A',\n",
       " 381: 'sasa_long_20A',\n",
       " 382: 'sasa_pro_20A',\n",
       " 383: 'sasa_A_polar_uncharged_with_hydroxyl_group_20A',\n",
       " 384: 'sasa_b_polar_uncharged_with_amide_20A',\n",
       " 385: 'sasa_d_negatively_charged_polar_20A',\n",
       " 386: 'sasa_e_non_polar_suffered_20A',\n",
       " 387: 'sasa_f_non_polar_aromatic_20A',\n",
       " 388: 'sasa_ala_20A',\n",
       " 389: 'sasa_cys_20A',\n",
       " 390: 'sasa_asp_20A',\n",
       " 391: 'sasa_glu_20A',\n",
       " 392: 'sasa_phe_20A',\n",
       " 393: 'sasa_his_20A',\n",
       " 394: 'sasa_ile_20A',\n",
       " 395: 'sasa_lys_20A',\n",
       " 396: 'sasa_leu_20A',\n",
       " 397: 'sasa_met_20A',\n",
       " 398: 'sasa_asn_20A',\n",
       " 399: 'sasa_gln_20A',\n",
       " 400: 'sasa_arg_20A',\n",
       " 401: 'sasa_ser_20A',\n",
       " 402: 'sasa_thr_20A',\n",
       " 403: 'sasa_val_20A',\n",
       " 404: 'sasa_trp_20A',\n",
       " 405: 'sasa_tyr_20A',\n",
       " 406: 'sasa_back_20A',\n",
       " 407: 'sasa_side_20A',\n",
       " 408: 'sasa_target_ser_thr_20A',\n",
       " 409: 'net_charge_all_20A',\n",
       " 410: 'net_charge_backbone_20A',\n",
       " 411: 'net_charge_sidechain_20A',\n",
       " 412: 'net_charge_all_exposed_20A',\n",
       " 413: 'net_charge_backbone_exposed_20A',\n",
       " 414: 'net_charge_sidechain_exposed_20A',\n",
       " 415: 'number_hydrophobic_25A',\n",
       " 416: 'number_hydrophilic_25A',\n",
       " 417: 'number_polar_25A',\n",
       " 418: 'number_aromatic_25A',\n",
       " 419: 'number_aliphatic_25A',\n",
       " 420: 'number_charged_25A',\n",
       " 421: 'number_positive_25A',\n",
       " 422: 'number_negative_25A',\n",
       " 423: 'number_gly_25A',\n",
       " 424: 'number_very_small_25A',\n",
       " 425: 'number_small_25A',\n",
       " 426: 'number_normal_25A',\n",
       " 427: 'number_long_25A',\n",
       " 428: 'number_pro_25A',\n",
       " 429: 'number_A_polar_uncharged_with_hydroxyl_group_25A',\n",
       " 430: 'number_b_polar_uncharged_with_amide_25A',\n",
       " 431: 'number_d_negatively_charged_polar_25A',\n",
       " 432: 'number_e_non_polar_suffered_25A',\n",
       " 433: 'number_f_non_polar_aromatic_25A',\n",
       " 434: 'number_ala_25A',\n",
       " 435: 'number_cys_25A',\n",
       " 436: 'number_asp_25A',\n",
       " 437: 'number_glu_25A',\n",
       " 438: 'number_phe_25A',\n",
       " 439: 'number_his_25A',\n",
       " 440: 'number_ile_25A',\n",
       " 441: 'number_lys_25A',\n",
       " 442: 'number_leu_25A',\n",
       " 443: 'number_met_25A',\n",
       " 444: 'number_asn_25A',\n",
       " 445: 'number_gln_25A',\n",
       " 446: 'number_arg_25A',\n",
       " 447: 'number_ser_25A',\n",
       " 448: 'number_thr_25A',\n",
       " 449: 'number_val_25A',\n",
       " 450: 'number_trp_25A',\n",
       " 451: 'number_tyr_25A',\n",
       " 452: 'sasa_hydrophobic_25A',\n",
       " 453: 'sasa_hydrophilic_25A',\n",
       " 454: 'sasa_polar_25A',\n",
       " 455: 'sasa_aromatic_25A',\n",
       " 456: 'sasa_aliphatic_25A',\n",
       " 457: 'sasa_charged_25A',\n",
       " 458: 'sasa_positive_25A',\n",
       " 459: 'sasa_negative_25A',\n",
       " 460: 'sasa_gly_25A',\n",
       " 461: 'sasa_very_small_25A',\n",
       " 462: 'sasa_small_25A',\n",
       " 463: 'sasa_normal_25A',\n",
       " 464: 'sasa_long_25A',\n",
       " 465: 'sasa_pro_25A',\n",
       " 466: 'sasa_A_polar_uncharged_with_hydroxyl_group_25A',\n",
       " 467: 'sasa_b_polar_uncharged_with_amide_25A',\n",
       " 468: 'sasa_d_negatively_charged_polar_25A',\n",
       " 469: 'sasa_e_non_polar_suffered_25A',\n",
       " 470: 'sasa_f_non_polar_aromatic_25A',\n",
       " 471: 'sasa_ala_25A',\n",
       " 472: 'sasa_cys_25A',\n",
       " 473: 'sasa_asp_25A',\n",
       " 474: 'sasa_glu_25A',\n",
       " 475: 'sasa_phe_25A',\n",
       " 476: 'sasa_his_25A',\n",
       " 477: 'sasa_ile_25A',\n",
       " 478: 'sasa_lys_25A',\n",
       " 479: 'sasa_leu_25A',\n",
       " 480: 'sasa_met_25A',\n",
       " 481: 'sasa_asn_25A',\n",
       " 482: 'sasa_gln_25A',\n",
       " 483: 'sasa_arg_25A',\n",
       " 484: 'sasa_ser_25A',\n",
       " 485: 'sasa_thr_25A',\n",
       " 486: 'sasa_val_25A',\n",
       " 487: 'sasa_trp_25A',\n",
       " 488: 'sasa_tyr_25A',\n",
       " 489: 'sasa_back_25A',\n",
       " 490: 'sasa_side_25A',\n",
       " 491: 'sasa_target_ser_thr_25A',\n",
       " 492: 'net_charge_all_25A',\n",
       " 493: 'net_charge_backbone_25A',\n",
       " 494: 'net_charge_sidechain_25A',\n",
       " 495: 'net_charge_all_exposed_25A',\n",
       " 496: 'net_charge_backbone_exposed_25A',\n",
       " 497: 'net_charge_sidechain_exposed_25A'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical features:\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "model_type = 'SLSTM_UP_AUGMENT_ONLY'\n",
    "\n",
    "augmented_columns = dict(pd.read_csv('./data/augmented_columns.csv', header=0).values.squeeze())\n",
    "print('# of augmented features:', len(augmented_columns))\n",
    "\n",
    "# set continuous input features\n",
    "x_cts = [x for x in augmented_columns.keys() if augmented_columns.get(x) != 'object']\n",
    "print('continuous features:')\n",
    "display(dict(zip(range(len(x_cts)), x_cts)))\n",
    "\n",
    "# set categorical input features\n",
    "x_cat = [x for x in augmented_columns.keys() if augmented_columns.get(x) == 'object']\n",
    "print('categorical features:')\n",
    "print(dict(zip(range(len(x_cat)), x_cat)))\n",
    "\n",
    "# input features\n",
    "x_var = x_cts + x_cat\n",
    "\n",
    "# set continuos output feature\n",
    "y_cts = []\n",
    "\n",
    "# set categorical output feature\n",
    "y_cat = ['positivity']\n",
    "\n",
    "# output features\n",
    "y_var = y_cts + y_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c2c79",
   "metadata": {},
   "source": [
    "# build amino acid sequence dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da184fcc",
   "metadata": {},
   "source": [
    "### model training with K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c7dc049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>input</th>\n",
       "      <th>hidden</th>\n",
       "      <th>lambda</th>\n",
       "      <th>train_2</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dnn_layers</th>\n",
       "      <th>f1_1</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>training_time</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.322</td>\n",
       "      <td>29.786</td>\n",
       "      <td>27.442</td>\n",
       "      <td>6.8262</td>\n",
       "      <td>0.351220</td>\n",
       "      <td>94.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.476</td>\n",
       "      <td>16.872</td>\n",
       "      <td>9.998</td>\n",
       "      <td>145.1884</td>\n",
       "      <td>0.569917</td>\n",
       "      <td>94.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.314</td>\n",
       "      <td>2.238</td>\n",
       "      <td>60.000</td>\n",
       "      <td>21.9834</td>\n",
       "      <td>0.724752</td>\n",
       "      <td>40.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.542</td>\n",
       "      <td>22.492</td>\n",
       "      <td>19.070</td>\n",
       "      <td>65.8448</td>\n",
       "      <td>0.484889</td>\n",
       "      <td>94.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.926</td>\n",
       "      <td>7.734</td>\n",
       "      <td>68.604</td>\n",
       "      <td>15.1434</td>\n",
       "      <td>0.636073</td>\n",
       "      <td>39.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.920</td>\n",
       "      <td>23.504</td>\n",
       "      <td>20.930</td>\n",
       "      <td>12.6094</td>\n",
       "      <td>0.493676</td>\n",
       "      <td>94.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.388</td>\n",
       "      <td>14.502</td>\n",
       "      <td>27.210</td>\n",
       "      <td>14.9144</td>\n",
       "      <td>0.513725</td>\n",
       "      <td>91.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.004</td>\n",
       "      <td>28.418</td>\n",
       "      <td>25.816</td>\n",
       "      <td>10.7458</td>\n",
       "      <td>0.472798</td>\n",
       "      <td>94.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.488</td>\n",
       "      <td>24.700</td>\n",
       "      <td>29.070</td>\n",
       "      <td>9.6366</td>\n",
       "      <td>0.421065</td>\n",
       "      <td>93.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.922</td>\n",
       "      <td>29.434</td>\n",
       "      <td>25.116</td>\n",
       "      <td>10.8158</td>\n",
       "      <td>0.412967</td>\n",
       "      <td>94.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.642</td>\n",
       "      <td>27.014</td>\n",
       "      <td>24.418</td>\n",
       "      <td>12.4658</td>\n",
       "      <td>0.431543</td>\n",
       "      <td>94.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.156</td>\n",
       "      <td>28.556</td>\n",
       "      <td>24.188</td>\n",
       "      <td>8.3962</td>\n",
       "      <td>0.404347</td>\n",
       "      <td>94.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.664</td>\n",
       "      <td>27.626</td>\n",
       "      <td>28.142</td>\n",
       "      <td>8.0614</td>\n",
       "      <td>0.365820</td>\n",
       "      <td>94.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.138</td>\n",
       "      <td>29.474</td>\n",
       "      <td>26.978</td>\n",
       "      <td>6.3808</td>\n",
       "      <td>0.307249</td>\n",
       "      <td>94.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.682</td>\n",
       "      <td>30.718</td>\n",
       "      <td>28.838</td>\n",
       "      <td>6.6166</td>\n",
       "      <td>0.345892</td>\n",
       "      <td>94.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.840</td>\n",
       "      <td>33.260</td>\n",
       "      <td>25.582</td>\n",
       "      <td>7.1942</td>\n",
       "      <td>0.342443</td>\n",
       "      <td>95.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.504</td>\n",
       "      <td>31.170</td>\n",
       "      <td>28.142</td>\n",
       "      <td>6.0756</td>\n",
       "      <td>0.335077</td>\n",
       "      <td>95.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.496</td>\n",
       "      <td>32.914</td>\n",
       "      <td>27.442</td>\n",
       "      <td>7.0466</td>\n",
       "      <td>0.358063</td>\n",
       "      <td>95.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.304</td>\n",
       "      <td>31.824</td>\n",
       "      <td>27.210</td>\n",
       "      <td>7.1612</td>\n",
       "      <td>0.345580</td>\n",
       "      <td>95.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.350</td>\n",
       "      <td>28.172</td>\n",
       "      <td>26.976</td>\n",
       "      <td>7.7300</td>\n",
       "      <td>0.330227</td>\n",
       "      <td>94.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.922</td>\n",
       "      <td>29.706</td>\n",
       "      <td>26.514</td>\n",
       "      <td>11.3676</td>\n",
       "      <td>0.321912</td>\n",
       "      <td>94.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.026</td>\n",
       "      <td>35.170</td>\n",
       "      <td>27.444</td>\n",
       "      <td>6.6402</td>\n",
       "      <td>0.308874</td>\n",
       "      <td>95.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.440</td>\n",
       "      <td>34.230</td>\n",
       "      <td>24.882</td>\n",
       "      <td>7.5266</td>\n",
       "      <td>0.312410</td>\n",
       "      <td>95.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.954</td>\n",
       "      <td>31.458</td>\n",
       "      <td>26.512</td>\n",
       "      <td>6.4688</td>\n",
       "      <td>0.350791</td>\n",
       "      <td>95.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.610</td>\n",
       "      <td>31.012</td>\n",
       "      <td>26.746</td>\n",
       "      <td>6.7866</td>\n",
       "      <td>0.359220</td>\n",
       "      <td>95.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.090</td>\n",
       "      <td>37.166</td>\n",
       "      <td>26.048</td>\n",
       "      <td>7.1666</td>\n",
       "      <td>0.287029</td>\n",
       "      <td>95.446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.622</td>\n",
       "      <td>30.908</td>\n",
       "      <td>27.208</td>\n",
       "      <td>7.9340</td>\n",
       "      <td>0.315029</td>\n",
       "      <td>95.040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cv_idx  input  hidden        lambda  train_2  rnn_layers  \\\n",
       "model_id                                                             \n",
       "1            2.0    0.0     0.0  0.000000e+00    498.0         5.0   \n",
       "2            2.0   21.0     0.0  1.000000e-03    498.0         5.0   \n",
       "3            2.0   21.0    21.0  1.000000e-03    498.0         5.0   \n",
       "4            2.0    1.0     0.0  1.000000e-03    498.0         5.0   \n",
       "5            2.0    1.0     1.0  1.000000e-03    498.0         5.0   \n",
       "6            2.0   21.0     0.0  1.000000e-04    498.0         5.0   \n",
       "7            2.0   21.0    21.0  1.000000e-04    498.0         5.0   \n",
       "8            2.0    1.0     0.0  1.000000e-04    498.0         5.0   \n",
       "9            2.0    1.0     1.0  1.000000e-04    498.0         5.0   \n",
       "10           2.0   21.0     0.0  1.000000e-05    498.0         5.0   \n",
       "11           2.0   21.0    21.0  1.000000e-05    498.0         5.0   \n",
       "12           2.0    1.0     0.0  1.000000e-05    498.0         5.0   \n",
       "13           2.0    1.0     1.0  1.000000e-05    498.0         5.0   \n",
       "14           2.0   21.0     0.0  1.000000e-06    498.0         5.0   \n",
       "15           2.0   21.0    21.0  1.000000e-06    498.0         5.0   \n",
       "16           2.0    1.0     0.0  1.000000e-06    498.0         5.0   \n",
       "17           2.0    1.0     1.0  1.000000e-06    498.0         5.0   \n",
       "18           2.0   21.0     0.0  1.000000e-07    498.0         5.0   \n",
       "19           2.0   21.0    21.0  1.000000e-07    498.0         5.0   \n",
       "20           2.0    1.0     0.0  1.000000e-07    498.0         5.0   \n",
       "21           2.0    1.0     1.0  1.000000e-07    498.0         5.0   \n",
       "22           2.0   21.0     0.0  1.000000e-08    498.0         5.0   \n",
       "23           2.0   21.0    21.0  1.000000e-08    498.0         5.0   \n",
       "24           2.0    1.0     0.0  1.000000e-08    498.0         5.0   \n",
       "25           2.0    1.0     1.0  1.000000e-08    498.0         5.0   \n",
       "26           2.0   21.0     0.0  1.000000e-09    498.0         5.0   \n",
       "27           2.0   21.0    21.0  1.000000e-09    498.0         5.0   \n",
       "\n",
       "          dnn_layers    f1_1  precision_1  recall_1  training_time  test_loss  \\\n",
       "model_id                                                                        \n",
       "1                3.0  28.322       29.786    27.442         6.8262   0.351220   \n",
       "2                3.0  12.476       16.872     9.998       145.1884   0.569917   \n",
       "3                3.0   4.314        2.238    60.000        21.9834   0.724752   \n",
       "4                3.0  20.542       22.492    19.070        65.8448   0.484889   \n",
       "5                3.0  10.926        7.734    68.604        15.1434   0.636073   \n",
       "6                3.0  21.920       23.504    20.930        12.6094   0.493676   \n",
       "7                3.0  18.388       14.502    27.210        14.9144   0.513725   \n",
       "8                3.0  27.004       28.418    25.816        10.7458   0.472798   \n",
       "9                3.0  26.488       24.700    29.070         9.6366   0.421065   \n",
       "10               3.0  26.922       29.434    25.116        10.8158   0.412967   \n",
       "11               3.0  25.642       27.014    24.418        12.4658   0.431543   \n",
       "12               3.0  26.156       28.556    24.188         8.3962   0.404347   \n",
       "13               3.0  27.664       27.626    28.142         8.0614   0.365820   \n",
       "14               3.0  28.138       29.474    26.978         6.3808   0.307249   \n",
       "15               3.0  29.682       30.718    28.838         6.6166   0.345892   \n",
       "16               3.0  28.840       33.260    25.582         7.1942   0.342443   \n",
       "17               3.0  29.504       31.170    28.142         6.0756   0.335077   \n",
       "18               3.0  29.496       32.914    27.442         7.0466   0.358063   \n",
       "19               3.0  29.304       31.824    27.210         7.1612   0.345580   \n",
       "20               3.0  27.350       28.172    26.976         7.7300   0.330227   \n",
       "21               3.0  27.922       29.706    26.514        11.3676   0.321912   \n",
       "22               3.0  30.026       35.170    27.444         6.6402   0.308874   \n",
       "23               3.0  28.440       34.230    24.882         7.5266   0.312410   \n",
       "24               3.0  27.954       31.458    26.512         6.4688   0.350791   \n",
       "25               3.0  28.610       31.012    26.746         6.7866   0.359220   \n",
       "26               3.0  30.090       37.166    26.048         7.1666   0.287029   \n",
       "27               3.0  28.622       30.908    27.208         7.9340   0.315029   \n",
       "\n",
       "          accuracy  \n",
       "model_id            \n",
       "1           94.892  \n",
       "2           94.728  \n",
       "3           40.746  \n",
       "4           94.562  \n",
       "5           39.254  \n",
       "6           94.502  \n",
       "7           91.136  \n",
       "8           94.796  \n",
       "9           93.982  \n",
       "10          94.928  \n",
       "11          94.720  \n",
       "12          94.918  \n",
       "13          94.546  \n",
       "14          94.882  \n",
       "15          94.918  \n",
       "16          95.288  \n",
       "17          95.022  \n",
       "18          95.178  \n",
       "19          95.106  \n",
       "20          94.746  \n",
       "21          94.910  \n",
       "22          95.186  \n",
       "23          95.334  \n",
       "24          95.004  \n",
       "25          95.074  \n",
       "26          95.446  \n",
       "27          95.040  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 36.36\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 77\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path) \u001b[38;5;129;01mor\u001b[39;00m model_update:\n\u001b[0;32m     76\u001b[0m     time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 77\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     81\u001b[0m     training_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m((time_end \u001b[38;5;241m-\u001b[39m time_start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32md:\\OneDrive\\Github\\glycosylation\\o-linked-site-prediction-feature-augment\\python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\OneDrive\\Github\\glycosylation\\o-linked-site-prediction-feature-augment\\python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\OneDrive\\Github\\glycosylation\\o-linked-site-prediction-feature-augment\\python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\OneDrive\\Github\\glycosylation\\o-linked-site-prediction-feature-augment\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\OneDrive\\Github\\glycosylation\\o-linked-site-prediction-feature-augment\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\OneDrive\\Github\\glycosylation\\o-linked-site-prediction-feature-augment\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\OneDrive\\Github\\glycosylation\\o-linked-site-prediction-feature-augment\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\OneDrive\\Github\\glycosylation\\o-linked-site-prediction-feature-augment\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\OneDrive\\Github\\glycosylation\\o-linked-site-prediction-feature-augment\\python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = initial_params.copy()\n",
    "keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "model_update = False\n",
    "\n",
    "MODELs = []\n",
    "METRICs = []\n",
    "METRIC_MEAN = []\n",
    "verbose = 0\n",
    "model_id = 1\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for name in protein_names:\n",
    "    data = pd.read_csv(f'./data/integrated_features/{name}.csv')\n",
    "    ST_idx = np.where((data['residue'] == 'S') | (data['residue'] == 'T'))[0]\n",
    "\n",
    "    # get X dataset\n",
    "    x_onehot = get_onehots(data[x_var], columns = x_cat)\n",
    "    x_features = list(x_onehot.columns)\n",
    "\n",
    "    # get Y dataset\n",
    "    y_onehot = get_onehots(data[y_var], columns = y_cat)\n",
    "    y_labels = list(y_onehot.columns)\n",
    "\n",
    "    for idx in ST_idx:\n",
    "        window_x = np.array(get_window(x_onehot, idx, params['window_size']))\n",
    "        label_y  = np.array(y_onehot.iloc[idx])\n",
    "\n",
    "        data_x.append(window_x)\n",
    "        data_y.append(label_y)\n",
    "\n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)\n",
    "\n",
    "model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params) # I don't know why, but this row is helping producing the same training result of a neural network\n",
    "\n",
    "print('data x shape:', data_x.shape)\n",
    "print('data y shape:', data_y.shape)\n",
    "print('class y counts:', data_y.sum(0))\n",
    "print(f'class y ratio: {(data_y.sum(0)/len(data_y)).round(4)}')\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits = 5, test_size = test_size, random_state = SEED)\n",
    "for regularizer in regularizers:\n",
    "    params['regularizer'] = regularizer\n",
    "    feature_weight = []\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    if METRICs:\n",
    "        display(pd.concat(METRICs, axis=0).groupby('model_id').mean())\n",
    "        # display(pd.concat(METRICs))\n",
    "    else:\n",
    "        display(METRICs)\n",
    "\n",
    "    for cv_idx, (train_idx, test_idx) in enumerate(splitter.split(data_x, data_y)):\n",
    "        train_x, train_y = data_x[train_idx], data_y[train_idx]\n",
    "        train_x, train_y = upsample_data(train_x, train_y) # up-sample the training dataset\n",
    "        test_x , test_y  = data_x[test_idx],  data_y[test_idx]\n",
    "\n",
    "        train_x, test_x = data_scaling(train_x, test_x)\n",
    "\n",
    "        model = LSTM_CLS(data_x.shape[1], data_x.shape[-1], data_y.shape[-1], params)\n",
    "        model_name = name_model(f'{model_type}', params)\n",
    "\n",
    "\n",
    "        model_folder  = f'./models/{model_name}_{data_x.shape}'\n",
    "        if not os.path.exists(model_folder):\n",
    "            os.makedirs(model_folder)\n",
    "        model_path    = f'{model_folder}/{cv_idx}.h5'\n",
    "        metric_path   = f'{model_folder}/{cv_idx}.csv'\n",
    "\n",
    "\n",
    "        if not os.path.exists(model_path) or model_update:\n",
    "            time_start = time.time()\n",
    "            history = model.fit(train_x, train_y, verbose=verbose,\n",
    "                                epochs = 10000, callbacks = callbacks,\n",
    "                                validation_split = test_size/(1-test_size))\n",
    "            time_end = time.time()\n",
    "            training_time = round((time_end - time_start)/60, 3)\n",
    "\n",
    "            model.save_weights(model_path)\n",
    "\n",
    "            test_loss, accuracy, precision, recall, f1 = metrics_classification(model, test_x, test_y)\n",
    "            model_metrics = {\n",
    "                'model_id' : model_id,\n",
    "                'cv_idx'   : cv_idx,\n",
    "                **{f'train_{x}': train_x.shape[x] for x in range(len(train_x.shape))},\n",
    "                'train_y'     : train_y.shape[-1],\n",
    "                'test_size'   : test_x.shape[0],\n",
    "                **params,\n",
    "                'regularizer_input' : params['regularizer']['input'],\n",
    "                'regularizer_hidden' : params['regularizer']['hidden'],\n",
    "                'regularizer_bias' : params['regularizer']['bias'],\n",
    "                'training_time': training_time,\n",
    "                'test_loss': test_loss,\n",
    "                'accuracy': accuracy,\n",
    "                **{f'precision_{x}': precision[x] for x in range(len(precision))},\n",
    "                **{f'recall_{x}'   : recall[x] for x in range(len(recall))},\n",
    "                **{f'f1_{x}'       : f1[x] for x in range(len(f1))}}\n",
    "            model_metrics = pd.DataFrame([model_metrics]).drop(['activation', 'loss', 'metrics', 'optimizer_type', 'regularizer'], axis=1)\n",
    "            model_metrics.to_csv(metric_path, index=False)\n",
    "\n",
    "        else:\n",
    "            model.load_weights(model_path)\n",
    "            model_metrics = pd.read_csv(metric_path, header=0)\n",
    "            model_metrics['model_id'] = model_id\n",
    "\n",
    "        weights = model.get_weights()\n",
    "        feature_weight.append(np.abs(weights[0]).mean(1).reshape(1,-1))\n",
    "\n",
    "        print(f'f1 score: {model_metrics.f1_1[0]}')\n",
    "\n",
    "        model_metrics['input']   = int(regularizer.get(\"input\", None).split('_')[0][1:]) if regularizer.get(\"input\", None) else 0\n",
    "        model_metrics['hidden']  = int(regularizer.get(\"hidden\", None).split('_')[0][1:]) if regularizer.get(\"hidden\", None) else 0\n",
    "        model_metrics['lambda']  = float(regularizer.get(\"input\", None).split('_')[1]) if regularizer.get(\"input\", None) else 0\n",
    "        METRICs.append(model_metrics[['model_id', 'cv_idx', 'input', 'hidden', 'lambda',\n",
    "                                     'train_2', 'rnn_layers', 'dnn_layers',\n",
    "                                     'f1_1', 'precision_1', 'recall_1', 'training_time', 'test_loss', 'accuracy']])\n",
    "\n",
    "    feature_weight = np.concatenate(feature_weight, axis=0)\n",
    "    feature_weight = feature_weight.mean(0)\n",
    "    feature_weight = pd.Series(feature_weight, index=x_features)\n",
    "    feature_weight.to_csv(f'./weights/{model_name}_{data_x.shape}.csv')\n",
    "    pd.concat(METRICs, axis=0).groupby('model_id').mean().to_csv('./figures/lambda and regularizer mean.csv')\n",
    "    pd.concat(METRICs, axis=0).to_csv('./figures/lambda and regularizer.csv')\n",
    "    model_id += 1\n",
    "\n",
    "METRICs = pd.concat(METRICs, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ac0e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>train_2</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dnn_layers</th>\n",
       "      <th>f1_1</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>training_time</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.322</td>\n",
       "      <td>29.786</td>\n",
       "      <td>27.442</td>\n",
       "      <td>6.8262</td>\n",
       "      <td>0.351220</td>\n",
       "      <td>94.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.476</td>\n",
       "      <td>16.872</td>\n",
       "      <td>9.998</td>\n",
       "      <td>145.1884</td>\n",
       "      <td>0.569917</td>\n",
       "      <td>94.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.314</td>\n",
       "      <td>2.238</td>\n",
       "      <td>60.000</td>\n",
       "      <td>21.9834</td>\n",
       "      <td>0.724752</td>\n",
       "      <td>40.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.542</td>\n",
       "      <td>22.492</td>\n",
       "      <td>19.070</td>\n",
       "      <td>65.8448</td>\n",
       "      <td>0.484889</td>\n",
       "      <td>94.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.926</td>\n",
       "      <td>7.734</td>\n",
       "      <td>68.604</td>\n",
       "      <td>15.1434</td>\n",
       "      <td>0.636073</td>\n",
       "      <td>39.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.920</td>\n",
       "      <td>23.504</td>\n",
       "      <td>20.930</td>\n",
       "      <td>12.6094</td>\n",
       "      <td>0.493676</td>\n",
       "      <td>94.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.388</td>\n",
       "      <td>14.502</td>\n",
       "      <td>27.210</td>\n",
       "      <td>14.9144</td>\n",
       "      <td>0.513725</td>\n",
       "      <td>91.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.004</td>\n",
       "      <td>28.418</td>\n",
       "      <td>25.816</td>\n",
       "      <td>10.7458</td>\n",
       "      <td>0.472798</td>\n",
       "      <td>94.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.488</td>\n",
       "      <td>24.700</td>\n",
       "      <td>29.070</td>\n",
       "      <td>9.6366</td>\n",
       "      <td>0.421065</td>\n",
       "      <td>93.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.922</td>\n",
       "      <td>29.434</td>\n",
       "      <td>25.116</td>\n",
       "      <td>10.8158</td>\n",
       "      <td>0.412967</td>\n",
       "      <td>94.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.642</td>\n",
       "      <td>27.014</td>\n",
       "      <td>24.418</td>\n",
       "      <td>12.4658</td>\n",
       "      <td>0.431543</td>\n",
       "      <td>94.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.156</td>\n",
       "      <td>28.556</td>\n",
       "      <td>24.188</td>\n",
       "      <td>8.3962</td>\n",
       "      <td>0.404347</td>\n",
       "      <td>94.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.664</td>\n",
       "      <td>27.626</td>\n",
       "      <td>28.142</td>\n",
       "      <td>8.0614</td>\n",
       "      <td>0.365820</td>\n",
       "      <td>94.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.138</td>\n",
       "      <td>29.474</td>\n",
       "      <td>26.978</td>\n",
       "      <td>6.3808</td>\n",
       "      <td>0.307249</td>\n",
       "      <td>94.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.682</td>\n",
       "      <td>30.718</td>\n",
       "      <td>28.838</td>\n",
       "      <td>6.6166</td>\n",
       "      <td>0.345892</td>\n",
       "      <td>94.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.840</td>\n",
       "      <td>33.260</td>\n",
       "      <td>25.582</td>\n",
       "      <td>7.1942</td>\n",
       "      <td>0.342443</td>\n",
       "      <td>95.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.504</td>\n",
       "      <td>31.170</td>\n",
       "      <td>28.142</td>\n",
       "      <td>6.0756</td>\n",
       "      <td>0.335077</td>\n",
       "      <td>95.022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cv_idx  train_2  rnn_layers  dnn_layers    f1_1  precision_1  \\\n",
       "model_id                                                                 \n",
       "1            2.0    498.0         5.0         3.0  28.322       29.786   \n",
       "2            2.0    498.0         5.0         3.0  12.476       16.872   \n",
       "3            2.0    498.0         5.0         3.0   4.314        2.238   \n",
       "4            2.0    498.0         5.0         3.0  20.542       22.492   \n",
       "5            2.0    498.0         5.0         3.0  10.926        7.734   \n",
       "6            2.0    498.0         5.0         3.0  21.920       23.504   \n",
       "7            2.0    498.0         5.0         3.0  18.388       14.502   \n",
       "8            2.0    498.0         5.0         3.0  27.004       28.418   \n",
       "9            2.0    498.0         5.0         3.0  26.488       24.700   \n",
       "10           2.0    498.0         5.0         3.0  26.922       29.434   \n",
       "11           2.0    498.0         5.0         3.0  25.642       27.014   \n",
       "12           2.0    498.0         5.0         3.0  26.156       28.556   \n",
       "13           2.0    498.0         5.0         3.0  27.664       27.626   \n",
       "14           2.0    498.0         5.0         3.0  28.138       29.474   \n",
       "15           2.0    498.0         5.0         3.0  29.682       30.718   \n",
       "16           2.0    498.0         5.0         3.0  28.840       33.260   \n",
       "17           2.0    498.0         5.0         3.0  29.504       31.170   \n",
       "\n",
       "          recall_1  training_time  test_loss  accuracy  \n",
       "model_id                                                \n",
       "1           27.442         6.8262   0.351220    94.892  \n",
       "2            9.998       145.1884   0.569917    94.728  \n",
       "3           60.000        21.9834   0.724752    40.746  \n",
       "4           19.070        65.8448   0.484889    94.562  \n",
       "5           68.604        15.1434   0.636073    39.254  \n",
       "6           20.930        12.6094   0.493676    94.502  \n",
       "7           27.210        14.9144   0.513725    91.136  \n",
       "8           25.816        10.7458   0.472798    94.796  \n",
       "9           29.070         9.6366   0.421065    93.982  \n",
       "10          25.116        10.8158   0.412967    94.928  \n",
       "11          24.418        12.4658   0.431543    94.720  \n",
       "12          24.188         8.3962   0.404347    94.918  \n",
       "13          28.142         8.0614   0.365820    94.546  \n",
       "14          26.978         6.3808   0.307249    94.882  \n",
       "15          28.838         6.6166   0.345892    94.918  \n",
       "16          25.582         7.1942   0.342443    95.288  \n",
       "17          28.142         6.0756   0.335077    95.022  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(METRICs.groupby('model_id').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00355cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_idx</th>\n",
       "      <th>train_2</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dnn_layers</th>\n",
       "      <th>f1_1</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>training_time</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.184420</td>\n",
       "      <td>2.540183</td>\n",
       "      <td>6.607683</td>\n",
       "      <td>1.569053</td>\n",
       "      <td>0.050139</td>\n",
       "      <td>0.289862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.162709</td>\n",
       "      <td>5.365330</td>\n",
       "      <td>2.265617</td>\n",
       "      <td>66.646721</td>\n",
       "      <td>0.126811</td>\n",
       "      <td>0.512903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.938125</td>\n",
       "      <td>2.043005</td>\n",
       "      <td>54.772256</td>\n",
       "      <td>3.548275</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>50.686245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.748028</td>\n",
       "      <td>4.240957</td>\n",
       "      <td>5.368682</td>\n",
       "      <td>18.112177</td>\n",
       "      <td>0.066994</td>\n",
       "      <td>0.288392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.338084</td>\n",
       "      <td>6.466937</td>\n",
       "      <td>43.849129</td>\n",
       "      <td>8.905815</td>\n",
       "      <td>0.116909</td>\n",
       "      <td>48.644630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.799234</td>\n",
       "      <td>4.506471</td>\n",
       "      <td>6.041490</td>\n",
       "      <td>4.240482</td>\n",
       "      <td>0.040712</td>\n",
       "      <td>0.509431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.731935</td>\n",
       "      <td>2.104417</td>\n",
       "      <td>9.138441</td>\n",
       "      <td>6.770135</td>\n",
       "      <td>0.024801</td>\n",
       "      <td>2.112044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.394886</td>\n",
       "      <td>2.760158</td>\n",
       "      <td>2.650251</td>\n",
       "      <td>2.247436</td>\n",
       "      <td>0.058648</td>\n",
       "      <td>0.286583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.467805</td>\n",
       "      <td>4.157782</td>\n",
       "      <td>5.134311</td>\n",
       "      <td>2.887524</td>\n",
       "      <td>0.035690</td>\n",
       "      <td>0.695068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.260768</td>\n",
       "      <td>3.358613</td>\n",
       "      <td>3.351474</td>\n",
       "      <td>4.295640</td>\n",
       "      <td>0.034567</td>\n",
       "      <td>0.399337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.967721</td>\n",
       "      <td>3.188178</td>\n",
       "      <td>2.849574</td>\n",
       "      <td>2.910762</td>\n",
       "      <td>0.039553</td>\n",
       "      <td>0.235797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.540409</td>\n",
       "      <td>2.357781</td>\n",
       "      <td>2.895405</td>\n",
       "      <td>2.181644</td>\n",
       "      <td>0.047886</td>\n",
       "      <td>0.177116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.187363</td>\n",
       "      <td>3.250366</td>\n",
       "      <td>5.477761</td>\n",
       "      <td>1.860242</td>\n",
       "      <td>0.047219</td>\n",
       "      <td>0.496568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.747001</td>\n",
       "      <td>7.842336</td>\n",
       "      <td>7.817904</td>\n",
       "      <td>1.755020</td>\n",
       "      <td>0.050148</td>\n",
       "      <td>0.503855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.587049</td>\n",
       "      <td>3.483370</td>\n",
       "      <td>4.303025</td>\n",
       "      <td>2.009447</td>\n",
       "      <td>0.043731</td>\n",
       "      <td>0.281904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.110330</td>\n",
       "      <td>4.523754</td>\n",
       "      <td>2.965277</td>\n",
       "      <td>0.863834</td>\n",
       "      <td>0.066577</td>\n",
       "      <td>0.319953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.684987</td>\n",
       "      <td>2.120943</td>\n",
       "      <td>4.958691</td>\n",
       "      <td>1.236870</td>\n",
       "      <td>0.044114</td>\n",
       "      <td>0.057184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cv_idx  train_2  rnn_layers  dnn_layers      f1_1  precision_1  \\\n",
       "model_id                                                                     \n",
       "1         1.581139      0.0         0.0         0.0  4.184420     2.540183   \n",
       "2         1.581139      0.0         0.0         0.0  3.162709     5.365330   \n",
       "3         1.581139      0.0         0.0         0.0  3.938125     2.043005   \n",
       "4         1.581139      0.0         0.0         0.0  4.748028     4.240957   \n",
       "5         1.581139      0.0         0.0         0.0  7.338084     6.466937   \n",
       "6         1.581139      0.0         0.0         0.0  4.799234     4.506471   \n",
       "7         1.581139      0.0         0.0         0.0  2.731935     2.104417   \n",
       "8         1.581139      0.0         0.0         0.0  2.394886     2.760158   \n",
       "9         1.581139      0.0         0.0         0.0  3.467805     4.157782   \n",
       "10        1.581139      0.0         0.0         0.0  2.260768     3.358613   \n",
       "11        1.581139      0.0         0.0         0.0  2.967721     3.188178   \n",
       "12        1.581139      0.0         0.0         0.0  2.540409     2.357781   \n",
       "13        1.581139      0.0         0.0         0.0  3.187363     3.250366   \n",
       "14        1.581139      0.0         0.0         0.0  7.747001     7.842336   \n",
       "15        1.581139      0.0         0.0         0.0  3.587049     3.483370   \n",
       "16        1.581139      0.0         0.0         0.0  3.110330     4.523754   \n",
       "17        1.581139      0.0         0.0         0.0  3.684987     2.120943   \n",
       "\n",
       "           recall_1  training_time  test_loss   accuracy  \n",
       "model_id                                                  \n",
       "1          6.607683       1.569053   0.050139   0.289862  \n",
       "2          2.265617      66.646721   0.126811   0.512903  \n",
       "3         54.772256       3.548275   0.002148  50.686245  \n",
       "4          5.368682      18.112177   0.066994   0.288392  \n",
       "5         43.849129       8.905815   0.116909  48.644630  \n",
       "6          6.041490       4.240482   0.040712   0.509431  \n",
       "7          9.138441       6.770135   0.024801   2.112044  \n",
       "8          2.650251       2.247436   0.058648   0.286583  \n",
       "9          5.134311       2.887524   0.035690   0.695068  \n",
       "10         3.351474       4.295640   0.034567   0.399337  \n",
       "11         2.849574       2.910762   0.039553   0.235797  \n",
       "12         2.895405       2.181644   0.047886   0.177116  \n",
       "13         5.477761       1.860242   0.047219   0.496568  \n",
       "14         7.817904       1.755020   0.050148   0.503855  \n",
       "15         4.303025       2.009447   0.043731   0.281904  \n",
       "16         2.965277       0.863834   0.066577   0.319953  \n",
       "17         4.958691       1.236870   0.044114   0.057184  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(METRICs.groupby('model_id').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e84284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
